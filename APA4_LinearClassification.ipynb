{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "apa",
      "language": "python",
      "name": "apa"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "272px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ic79bzJP9RCi"
      },
      "source": [
        "# APA Laboratori 5  - LDA/QDA/NBayes/RegLog      "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-15T10:05:02.512700Z",
          "start_time": "2020-07-15T10:05:02.498782Z"
        },
        "scrolled": true,
        "id": "gCNGOL8i9RCl"
      },
      "source": [
        "# Uncomment to upgrade packages\n",
        "# !pip install pandas --upgrade --user --quiet\n",
        "# !pip install numpy --upgrade --user --quiet\n",
        "# !pip install scipy --upgrade --user --quiet\n",
        "# !pip install statsmodels --upgrade --user --quiet\n",
        "# !pip install scikit-learn --upgrade --user --quiet\n",
        "# !pip install seaborn --upgrade --user --quiet\n",
        "%load_ext autoreload"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-15T10:05:03.397081Z",
          "start_time": "2020-07-15T10:05:02.515074Z"
        },
        "id": "oaWjs4lX9RCn"
      },
      "source": [
        "#%matplotlib notebook\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "pd.set_option('precision', 3)\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-15T10:07:09.579470Z",
          "start_time": "2020-07-15T10:07:09.388252Z"
        },
        "id": "sSYvIaUo9RCp"
      },
      "source": [
        "# Extra imports\n",
        "from pandas import read_csv\n",
        "from sklearn.metrics import confusion_matrix, \\\n",
        "                  classification_report, accuracy_score\n",
        "from pandas.api.types import CategoricalDtype\n",
        "from pandas.plotting import scatter_matrix\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import BernoulliNB, GaussianNB, CategoricalNB\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from numpy.random import  normal, binomial\n",
        "from statsmodels.genmod.generalized_linear_model import GLM\n",
        "from statsmodels.genmod.families.family import Binomial\n",
        "from statsmodels.tools.tools import add_constant\n",
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-15T10:07:11.921474Z",
          "start_time": "2020-07-15T10:07:11.918308Z"
        },
        "id": "NZfHSAsx9RCq"
      },
      "source": [
        "def confusion(true, pred, classes):\n",
        "    \"\"\"\n",
        "    Function for pretty printing confusion matrices\n",
        "    \"\"\"\n",
        "    cm =pd.DataFrame(confusion_matrix(true, pred), \n",
        "                     index=classes,\n",
        "                     columns=classes)\n",
        "    cm.index.name = 'Actual'\n",
        "    cm.columns.name = 'Predicted'\n",
        "    return cm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLxGF5Qr9RCr"
      },
      "source": [
        "## Example 1: Visualizing and classifying wines with LDA and QDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXQdg89R9RCs"
      },
      "source": [
        " We have the results of an analysis on wines grown in a region in Italy but derived from three different cultivars.\n",
        "The analysis determined the quantities of 13 chemical constituents found in each of the three types of wines. \n",
        "The goal is to separate the three types of wines:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-15T10:07:15.915970Z",
          "start_time": "2020-07-15T10:07:15.885095Z"
        },
        "id": "ZnkGThIW9RCu"
      },
      "source": [
        "wine = read_csv(\"wine.data\", delimiter=',', header=None)\n",
        "wine_classes = ['cultivar %d'%(i+1) for i in range(3)]\n",
        "wine.shape\n",
        "wine.columns = ['Wine_type','Alcohol','Malic_acid','Ash',\n",
        "                'Alcalinity_of_ash','Magnesium','Total_phenols',\n",
        "                'Flavanoids','Nonflavanoid_phenols',\n",
        "                'Proanthocyanins','Color_intensity','Hue',\n",
        "                'OD280/OD315','Proline']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-15T10:07:16.498543Z",
          "start_time": "2020-07-15T10:07:16.452385Z"
        },
        "scrolled": true,
        "id": "mbLkHOLh9RCv"
      },
      "source": [
        "wine.Wine_type = wine.Wine_type.astype(CategoricalDtype(categories=[1, 2, 3],  \n",
        "                                                        ordered=True))\n",
        "wine.describe(include='all')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-15T10:07:23.273322Z",
          "start_time": "2020-07-15T10:07:16.889883Z"
        },
        "id": "gkd1VB2s9RCx"
      },
      "source": [
        "scatter_matrix(wine.loc[:,'Alcohol':'Proline'], \n",
        "               alpha=0.2, figsize=(16, 16), \n",
        "               diagonal='kde',marker='.',\n",
        "               c=wine.Wine_type);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rSt5q6-9RCy"
      },
      "source": [
        "### LDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3yTI_md9RCz"
      },
      "source": [
        "LDA tries to model the probability $p(y=C_k|X=x)$ by assuming: \n",
        "* $p(x|C_k)$ is Gaussian (which means that can be described by $\\mu_k$ and $\\Sigma_k$)\n",
        "* All covariance matrix are the same ($\\Sigma_k = \\Sigma$)\n",
        "\n",
        "By using bayes formula ($p(A|B) = \\frac{P(B|A)P(A)}{P(B)}$) and all these asumptions, we obtain the next discriminant function:\n",
        "\n",
        "$a_k(x) = x^T\\Sigma^{-1}\\mu_k - \\frac{1}{2}\\mu_k^T\\Sigma^{-1}\\mu_k + log(\\pi_k)$\n",
        "\n",
        "Where $\\pi_k$ are the prior probabilities. \n",
        "\n",
        "If we call:\n",
        "\n",
        "$w = \\Sigma^{-1}\\mu_k$\n",
        "\n",
        "$w_0=- \\frac{1}{2}\\mu_k^T\\Sigma^{-1}\\mu_k + log(\\pi_k)$\n",
        "\n",
        "We obtain a linear representation of the formula."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoJ5Yr-S9RCz"
      },
      "source": [
        "For this example let's practice a different call mode to lda(), using a formula; this is most useful\n",
        " when our data is in a dataframe format: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-15T10:07:23.306024Z",
          "start_time": "2020-07-15T10:07:23.274811Z"
        },
        "scrolled": true,
        "id": "OzGc_k6Y9RC0"
      },
      "source": [
        "lda_model = LinearDiscriminantAnalysis().fit(wine.loc[:,'Alcohol':'Proline'],\n",
        "                                             wine.Wine_type)\n",
        "\n",
        "print('Priors:', lda_model.priors_)\n",
        "print('Means:\\n')\n",
        "means =pd.DataFrame(lda_model.means_)\n",
        "means.columns=wine.columns[1:]\n",
        "means\n",
        "print('Coefs:')\n",
        "coefs = pd.DataFrame(lda_model.coef_)\n",
        "coefs.columns =wine.columns[1:]\n",
        "coefs.T\n",
        "\n",
        "print('Intercepts:')\n",
        "intercepts = pd.DataFrame(lda_model.intercept_)\n",
        "intercepts\n",
        "\n",
        "print('Explained Variance Ratio')\n",
        "pd.DataFrame(lda_model.explained_variance_ratio_ )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPqUqmDd9RC1"
      },
      "source": [
        "We can see that neither Magnesium or Proline seem useful to separate the wines; while\n",
        " Flavanoids and Nonflavanoid.phenols do. Ash is mainly used in the LD2.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpNEJWeM9RC1"
      },
      "source": [
        "Here we have an example of how the model is predicting the class of a single sample."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62Wp-dAe9RC2"
      },
      "source": [
        "sample = wine.loc[0,'Alcohol':'Proline']\n",
        "sample_value = wine.loc[0,'Wine_type']\n",
        "\n",
        "wine.loc[0,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3QfF2of9RC2"
      },
      "source": [
        "lda_model.predict(sample.values.reshape(1, -1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJuUbLyX9RC3"
      },
      "source": [
        "lda_model.decision_function(sample.values.reshape(1, -1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jf6oyo4Z9RC3"
      },
      "source": [
        "np.matmul(lda_model.coef_, sample) + lda_model.intercept_\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxgQvPYw9RC4"
      },
      "source": [
        "Plot the projected data in the first two LDs\n",
        "\n",
        " We can see that the discrimination is very good"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-15T10:07:23.612444Z",
          "start_time": "2020-07-15T10:07:23.307833Z"
        },
        "id": "PLY3dkVf9RC4"
      },
      "source": [
        "wine_trans = lda_model.transform(wine.loc[:,'Alcohol':'Proline'])\n",
        "fig, ax = plt.subplots(figsize=(8,8))\n",
        "for i in wine.Wine_type.unique():\n",
        "    plt.scatter(wine_trans[:,0][wine.Wine_type==i],\n",
        "                wine_trans[:,1][wine.Wine_type==i],\n",
        "                label='cultivar %d'%i)\n",
        "ax.set_xlabel('LD1')\n",
        "ax.set_ylabel('LD2')\n",
        "plt.legend();\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOio_W0V9RC5"
      },
      "source": [
        " If need be, we can add the (projected) means to the plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-15T10:07:23.791596Z",
          "start_time": "2020-07-15T10:07:23.614633Z"
        },
        "id": "2kDWe96B9RC5"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(8,8))\n",
        "for i in wine.Wine_type.unique():\n",
        "    plt.scatter(wine_trans[:,0][wine.Wine_type==i],\n",
        "                wine_trans[:,1][wine.Wine_type==i],\n",
        "                label='cultivar %d'%i)\n",
        "    plt.plot(wine_trans[:,0][wine.Wine_type==i].mean(),\n",
        "             wine_trans[:,1][wine.Wine_type==i].mean(),\n",
        "             'k^',markersize=20)\n",
        "ax.set_xlabel('LD1')\n",
        "ax.set_ylabel('LD2')\n",
        "plt.legend();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwTxQT0S9RC6"
      },
      "source": [
        "indeed classification is perfect"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-15T10:07:23.804120Z",
          "start_time": "2020-07-15T10:07:23.793135Z"
        },
        "id": "EL62RvMC9RC6"
      },
      "source": [
        "confusion(wine.Wine_type, lda_model.predict(wine.loc[:,'Alcohol':'Proline']), \n",
        "          classes=wine_classes)          "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_QMd67o9RC7"
      },
      "source": [
        "Let us switch to leave-one-out cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-15T10:07:23.929570Z",
          "start_time": "2020-07-15T10:07:23.806172Z"
        },
        "id": "lRK245Lr9RC7"
      },
      "source": [
        "def loocv(X,y,model,classes):\n",
        "    loo = LeaveOneOut()\n",
        "    pred=[]\n",
        "    for train_index, test_index in loo.split(X):\n",
        "        X_tr, X_ts = X[train_index], X[test_index]\n",
        "        y_tr, _ = y[train_index], y[test_index]\n",
        "        model.fit(X_tr,y_tr)\n",
        "        pred.append(model.predict(X_ts)[0])\n",
        "    return confusion(y,pred,classes), 1-accuracy_score(y,pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-15T10:07:24.360928Z",
          "start_time": "2020-07-15T10:07:23.931474Z"
        },
        "id": "41u50E-r9RC7"
      },
      "source": [
        "cm, err = loocv(wine.loc[:,'Alcohol':'Proline'].values, \n",
        "                wine.Wine_type, \n",
        "                LinearDiscriminantAnalysis(),\n",
        "                wine_classes)\n",
        "\n",
        "cm\n",
        "\n",
        "err*100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52fKhRti9RC8"
      },
      "source": [
        "2 mistakes (on 178 observations): 1.12% error\n",
        "\n",
        "Quadratic Discriminant Analysis is the same\n",
        "\n",
        " problems may arise if for some class there are less (or equal) observations than dimensions\n",
        " (is not the case for the wine data)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-15T10:07:24.398030Z",
          "start_time": "2020-07-15T10:07:24.363735Z"
        },
        "id": "UW6PN2_H9RC8"
      },
      "source": [
        "qda_model = QuadraticDiscriminantAnalysis().fit(wine.loc[:,'Alcohol':'Proline'],\n",
        "                                                wine.Wine_type)\n",
        "\n",
        "print('Priors:\\n')\n",
        "pd.DataFrame(qda_model.priors_)\n",
        "print('Means:\\n')\n",
        "means =pd.DataFrame(qda_model.means_)\n",
        "means.columns=wine.columns[1:]\n",
        "means"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zL3nKknL9RC8"
      },
      "source": [
        " There is no projection this time (because projection is a linear operator and the QDA boundaries are quadratic ones)\n",
        "\n",
        " but let's have a look at classification:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-15T10:07:24.505617Z",
          "start_time": "2020-07-15T10:07:24.399832Z"
        },
        "id": "dz9tbCG79RC8"
      },
      "source": [
        "confusion(wine.Wine_type, qda_model.predict(wine.loc[:,'Alcohol':'Proline']), \n",
        "          classes=wine_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4_D54rC9RC8"
      },
      "source": [
        "Let us switch to leave-one-out cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-15T10:07:24.950371Z",
          "start_time": "2020-07-15T10:07:24.507660Z"
        },
        "id": "WXmOPHk39RC9"
      },
      "source": [
        "cm, err = loocv(wine.loc[:,'Alcohol':'Proline'].values,\n",
        "                wine.Wine_type, \n",
        "                QuadraticDiscriminantAnalysis(),\n",
        "                wine_classes)\n",
        "\n",
        "cm\n",
        "\n",
        "err*100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uWrZYFN9RC9"
      },
      "source": [
        "1 mistake (on 178 observations): 0.56% error\n",
        "\n",
        " it would be nice to ascertain which wine is the \"stubborn\" one: it is a wine of type '2' classified\n",
        "as class '1'. Maybe there is something special with this wine ...\n",
        "\n",
        " In the event of numerical errors (insufficient number of observations per class), we can use regularization.\n",
        " \n",
        " in this case the regularization parameter (0..1) is applied to the covariance matrix (Sigma) so it is not ill conditioned in this fashion\n",
        " \n",
        " `(1-reg_param)*Sigma + reg_param*np.eye(n_features)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8To692e9RC9"
      },
      "source": [
        "### QDA\n",
        "\n",
        "QDA is very similar to LDA. The main difference is that in this model we do not assume that all the classes have the same covariance. This leads to obtaining a quadratic decision surface."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-15T10:07:25.256206Z",
          "start_time": "2020-07-15T10:07:25.236929Z"
        },
        "id": "k-hN9CbN9RC9"
      },
      "source": [
        "qda_model = QuadraticDiscriminantAnalysis(reg_param=0.1).\\\n",
        "                    fit(wine.loc[:,'Alcohol':'Proline'],\n",
        "                        wine.Wine_type)\n",
        "\n",
        "print('Priors:', qda_model.priors_)\n",
        "print('Means:\\n')\n",
        "means =pd.DataFrame(qda_model.means_)\n",
        "means.columns=wine.columns[1:]\n",
        "means"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-15T10:07:25.699641Z",
          "start_time": "2020-07-15T10:07:25.687999Z"
        },
        "id": "go1yg8rJ9RC9"
      },
      "source": [
        "confusion(wine.Wine_type, qda_model.predict(wine.loc[:,'Alcohol':'Proline']), \n",
        "          classes=wine_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpj_KaRa9RC-"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5fAM7Tm9RC-"
      },
      "source": [
        "## Example 2: The Na√Øve Bayes classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2emzKfUx9RC-"
      },
      "source": [
        "Naive Bayes model will assume assume that the attributes of the class conditional probabilities are independent and a certain distribution for them bassed on the kind of data we are working with. \n",
        "\n",
        "For example: if we are working with numerical variables it will assume that the features are conditionally independent between them and that they follow a gaussian distribution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9Rd7lID9RC-"
      },
      "source": [
        "### Naive Bayes on binary data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bM5mGnsu9RC-"
      },
      "source": [
        " Naive Bayes Classifier for Discrete Predictors: we use the \n",
        " 1984 United States Congressional Voting Records; \n",
        "\n",
        " This data set includes votes for each of the U.S. House of Representatives Congressmen on 16 key votes\n",
        "In origin they were nine different types of votes: \n",
        "     \n",
        "* voted for, paired for, and announced for (these three simplified to yea or 'y'),\n",
        "* voted against, paired against, and announced against (these three simplified to nay or 'n'), \n",
        "* voted present, voted present to avoid conflict of interest, and did not vote or otherwise make a position known \n",
        "     (these three simplified to an 'unknown' disposition)\n",
        "\n",
        " The goal is to classify Congressmen as Republican or Democrat as a function of their voting profiles,\n",
        "which is not immediate because in the US Congressmen have a large freedom of vote \n",
        " (obviously linked to their party but also to their own feelings, interests and compromises with voters)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-15T10:07:27.656317Z",
          "start_time": "2020-07-15T10:07:27.650670Z"
        },
        "id": "ocD84Rx89RC_"
      },
      "source": [
        "HouseVotes84 = read_csv(\"house-votes-84.data\", \n",
        "                        delimiter=',', \n",
        "                        header=None,na_values='?')\n",
        "house_classes = ['democrat','republican']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wiij3X5K9RC_"
      },
      "source": [
        "add meaningful names to the votes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-15T10:07:28.332139Z",
          "start_time": "2020-07-15T10:07:28.285248Z"
        },
        "id": "eK-hX8hu9RC_"
      },
      "source": [
        "HouseVotes84.columns=[\"Class\",\"handicapped_infants\",\"water_project_sharing\",\n",
        "                      \"budget_resolution\",\"physician_fee_freeze\",\n",
        "                      \"el_salvador_aid\",\"religious_groups_in_schools\",\n",
        "                      \"anti_satellite_ban\", \"aid_to_nicaraguan_contras\",\n",
        "                      \"mx_missile\",\"immigration\",\"synfuels_cutback\",\n",
        "                      \"education_spending\",\"superfund\",\"crime\",\n",
        "                      \"duty_free_exports\",\"export_South_Africa\"]\n",
        "HouseVotes84.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNPaiult9RC_"
      },
      "source": [
        "HouseVotes84.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-15T10:07:28.769882Z",
          "start_time": "2020-07-15T10:07:28.721762Z"
        },
        "id": "bWl_VZIq9RDA"
      },
      "source": [
        "for v in HouseVotes84.columns:\n",
        "    HouseVotes84[v].value_counts(dropna=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTBTn94k9RDA"
      },
      "source": [
        "1 = democrat, 0 = republican\n",
        " Note \"unknown dispositions\" have been treated as missing values!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BMZK7RN9RDA"
      },
      "source": [
        "The naive bayes implementations of scikit-learn do not allow missing values and also need binary data, so we will preprocess first changing *y* for 1 and *n* for 0 and then we perform missing data imputation. Another option would be to eliminate all rows with missing, but that will discard half of the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-15T10:07:29.923148Z",
          "start_time": "2020-07-15T10:07:29.902283Z"
        },
        "id": "9VbV54Pq9RDA"
      },
      "source": [
        "HouseVotes84.replace({'y':1, 'n':0},inplace=True)\n",
        "HouseVotes84.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlwwl01c9RDA"
      },
      "source": [
        "We use the most frequent value from each column for imputation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-15T10:07:42.013443Z",
          "start_time": "2020-07-15T10:07:41.973433Z"
        },
        "id": "YFrGG9wQ9RDB"
      },
      "source": [
        "HouseVotes84.loc[:,'handicapped_infants':] =  SimpleImputer(strategy='most_frequent').\\\n",
        "                fit_transform(HouseVotes84.loc[:,'handicapped_infants':])\n",
        "HouseVotes84.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-15T10:07:43.141111Z",
          "start_time": "2020-07-15T10:07:43.138667Z"
        },
        "id": "7Sd0xvdY9RDB"
      },
      "source": [
        "np.random.seed(1111)\n",
        "N = HouseVotes84.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYbEPtrG9RDB"
      },
      "source": [
        " We first split the available data into learning and test sets, selecting randomly 2/3 and 1/3 of the data.\n",
        " \n",
        " We do this for a honest estimation of prediction performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-15T10:07:44.340568Z",
          "start_time": "2020-07-15T10:07:44.336395Z"
        },
        "id": "rXAjkLOS9RDB"
      },
      "source": [
        "train, test = train_test_split(HouseVotes84, test_size=N//3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wolrxxk9RDB"
      },
      "source": [
        "We use the BernoulliNB estimator because we have binary data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-15T10:07:45.657041Z",
          "start_time": "2020-07-15T10:07:45.635348Z"
        },
        "id": "iuYmWYU19RDC"
      },
      "source": [
        "model = BernoulliNB().fit(train.loc[:,'handicapped_infants':], \n",
        "                          train.Class)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEmMOJCJ9RDC"
      },
      "source": [
        "To obtain the probabiblities from the model is a little bit tricky. \n",
        "\n",
        "The attribute `class_log_prior_` stores the priot log probabilities for the classes, so we can compute the probabilities doing:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-15T10:07:46.657566Z",
          "start_time": "2020-07-15T10:07:46.653686Z"
        },
        "id": "HwkgNNk79RDC"
      },
      "source": [
        "np.e**model.class_log_prior_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXRqrRDU9RDC"
      },
      "source": [
        "For the attributes/class probabilities is trickier because ony one of the probabilities is stored (the othe is the complement) and also are the log probabilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-15T10:07:48.969949Z",
          "start_time": "2020-07-15T10:07:48.954766Z"
        },
        "id": "k2Sh0Wcz9RDC"
      },
      "source": [
        "probs=pd.DataFrame({'Democrat Y':np.e**model.feature_log_prob_.T[:,0],\n",
        "                    'Democrat N':1-np.e**model.feature_log_prob_.T[:,0],\n",
        "                    'Republican Y':np.e**model.feature_log_prob_.T[:,1], \n",
        "                    'Republican N':1-np.e**model.feature_log_prob_.T[:,1]},\n",
        "                    index=HouseVotes84.columns[1:])\n",
        "\n",
        "probs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tXxYuCL9RDD"
      },
      "source": [
        "predict the outcome of the first 20 Congressmen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-15T10:07:50.074012Z",
          "start_time": "2020-07-15T10:07:50.068148Z"
        },
        "id": "2n8Bk_TE9RDD"
      },
      "source": [
        "model.predict(HouseVotes84.loc[0:20,'handicapped_infants':])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-15T10:07:50.631477Z",
          "start_time": "2020-07-15T10:07:50.619922Z"
        },
        "id": "mMmF_NHG9RDD"
      },
      "source": [
        "pred=pd.DataFrame(model.predict_proba(HouseVotes84.loc[0:20,'handicapped_infants':]))\n",
        "\n",
        "pred.columns=['democrat', 'republican']\n",
        "pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHmsm-m-9RDD"
      },
      "source": [
        "form and display confusion matrix & overall error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-15T10:07:51.753562Z",
          "start_time": "2020-07-15T10:07:51.736894Z"
        },
        "id": "HZ_vVOa49RDD"
      },
      "source": [
        "confusion(train.Class, model.predict(train.loc[:,'handicapped_infants':]), \n",
        "          classes=house_classes)\n",
        "\n",
        "(1-accuracy_score(train.Class, \n",
        "                  model.predict(train.loc[:,'handicapped_infants':])))*100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95wE4bZQ9RDD"
      },
      "source": [
        "compute the test (prediction) error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-15T10:07:52.819670Z",
          "start_time": "2020-07-15T10:07:52.804518Z"
        },
        "scrolled": true,
        "id": "ucLFE3Qv9RDE"
      },
      "source": [
        "confusion(test.Class,\n",
        "          model.predict(test.loc[:,'handicapped_infants':]), \n",
        "          classes=house_classes)\n",
        "\n",
        "(1-accuracy_score(test.Class,\n",
        "                  model.predict(test.loc[:,'handicapped_infants':])))*100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2H8JIPkB9RDE"
      },
      "source": [
        " note how most errors (10/12) correspond to democrats wrongly predicted as republicans\n",
        "\n",
        "in the event of **empty empirical probabilities**, there is an alpha parameter (0-1) that can be use for performing Laplace correction (aka smoothing) (0 = no smoothing)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-15T10:07:53.992375Z",
          "start_time": "2020-07-15T10:07:53.986338Z"
        },
        "id": "j-sNM_Oo9RDE"
      },
      "source": [
        "model = BernoulliNB(alpha=0.6).fit(train.loc[:,'handicapped_infants':], \n",
        "                                   train.Class)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYujNiT39RDE"
      },
      "source": [
        "### Naive Bayes on mixed data types\n",
        "\n",
        "Now we are going to work with mixed data types using the heart dataset (https://www.kaggle.com/ronitf/heart-disease-uci). \n",
        "\n",
        "Our goal now is predict if a patient has a heart disease using medical data. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3ybzdO59RDE"
      },
      "source": [
        "income = pd.read_csv('census_income_weka_dataset.csv')\n",
        "\n",
        "categorical = ['workclass', 'education', 'marital_status', 'occupation',\n",
        "       'relationship', 'race', 'sex', 'native_country']\n",
        "numerical = ['age', 'fnlwgt', 'education_num', 'capital_gain', 'capital_loss',\n",
        "       'hours_per_week']\n",
        "\n",
        "target= 'income_level'\n",
        "\n",
        "for c in categorical:\n",
        "    income[c]=income[c].astype(CategoricalDtype())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Lj_1glOO9RDE"
      },
      "source": [
        "for c in income.columns:\n",
        "    if c in categorical:\n",
        "        sn.countplot(x=c,data=income,hue='income_level')\n",
        "        a =plt.xticks(rotation= 90)\n",
        "    else:\n",
        "        sn.histplot(x=c,data=income,hue='income_level')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Z9Uzmg39RDF"
      },
      "source": [
        "As this model assumes independence between features, we can split the dataset by data type and apply two different Naive Bayes models. One Gaussian for the numerical variables and one Categorical for the categorical ones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmTniGnM9RDF"
      },
      "source": [
        "def preprocessing_categorical(X):\n",
        "    for c in X.columns:\n",
        "        X[c]=X[c].cat.codes\n",
        "    return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9e-TyOP9RDF"
      },
      "source": [
        "We split into train, val and test because we want to compare the results of the different models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqD_Rr-o9RDF"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(income[categorical + numerical],income[target],  test_size=0.2)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
        "\n",
        "\n",
        "X_train_numerical = X_train[numerical]\n",
        "X_train_categorical = X_train[categorical]\n",
        "X_train_categorical = preprocessing_categorical(X_train_categorical)\n",
        "\n",
        "X_val_numerical = X_val[numerical]\n",
        "X_val_categorical = X_val[categorical]\n",
        "X_val_categorical = preprocessing_categorical(X_val_categorical)\n",
        "\n",
        "X_test_numerical = X_test[numerical]\n",
        "X_test_categorical = X_test[categorical]\n",
        "X_test_categorical = preprocessing_categorical(X_test_categorical)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WENslkZB9RDF"
      },
      "source": [
        "Now we train the Gaussian model with the numerical variables and the categorical with the categorical one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgkqlkB-9RDG"
      },
      "source": [
        "gaussian_nb = GaussianNB()\n",
        "\n",
        "gaussian_nb.fit(X_train_numerical,y_train)\n",
        "\n",
        "gaussian_nb.score(X_val_numerical,y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0i7-tKmd9RDG"
      },
      "source": [
        "cat_nb = CategoricalNB()\n",
        "cat_nb.fit(X_train_categorical,y_train)\n",
        "\n",
        "cat_nb.score(X_val_categorical,y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZqVI_kY9RDG"
      },
      "source": [
        "Now we can multiply the probabilities to classify."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DU8RlYbs9RDG"
      },
      "source": [
        "combined_prediction_proba= cat_nb.predict_proba(X_val_categorical) * gaussian_nb.predict_proba(X_val_numerical)\n",
        "\n",
        "combined_prediction = np.argmax(combined_prediction_proba,axis=1)\n",
        "clases = {0:'<=50K',1:'>50K'}\n",
        "combined_prediction = [clases[v] for v in combined_prediction]\n",
        "accuracy_score(combined_prediction, y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Y91jVr09RDG"
      },
      "source": [
        "This way we obtain a better validation accuracy. \n",
        "Now we are going to analyze the generalization error on the test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTzJt5wl9RDH"
      },
      "source": [
        "test_combined_prediction_proba= cat_nb.predict_proba(X_test_categorical) * gaussian_nb.predict_proba(X_test_numerical)\n",
        "\n",
        "test_combined_prediction = np.argmax(test_combined_prediction_proba,axis=1)\n",
        "clases = {0:'<=50K',1:'>50K'}\n",
        "test_combined_prediction = [clases[v] for v in test_combined_prediction]\n",
        "accuracy_score(test_combined_prediction, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "oHcINY379RDH"
      },
      "source": [
        "confusion(test_combined_prediction, y_test,['<=50K','>50K'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tkJJhKR9RDH"
      },
      "source": [
        "fpr, tpr, _ = metrics.roc_curve(y_test=='<=50K',  test_combined_prediction_proba[:,0])\n",
        "auc = metrics.roc_auc_score(y_test=='<=50K',  test_combined_prediction_proba[:,0])\n",
        "plt.plot(fpr,tpr,label=\"<=50K, auc=\"+str(auc))\n",
        "\n",
        "fpr, tpr, _ = metrics.roc_curve(y_test=='>50K',  test_combined_prediction_proba[:,1])\n",
        "auc = metrics.roc_auc_score(y_test=='>50K',  test_combined_prediction_proba[:,1])\n",
        "plt.plot(fpr,tpr,label=\">50K, auc=\"+str(auc))\n",
        "\n",
        "plt.legend(loc=4)\n",
        "plt.ylabel('True positive rate')\n",
        "plt.xlabel('False positive rate')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wbO6Ln09RDH"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrgBQ3TW9RDH"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZpVv-9f9RDH"
      },
      "source": [
        "## Example 3: Logistic Regression using artificial data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0diS8Ky9RDI"
      },
      "source": [
        "The goal of this example is to get acquainted with the call to glm()\n",
        " glm() is used to fit generalized linear models (of which both linear and logistic regression are particular cases)\n",
        "\n",
        " You may need to recall at this point the logistic regression model ...\n",
        "\n",
        " Let $x$ represent a single continuous predictor\n",
        " \n",
        " Let $y$ represent a class ('0' or '1'), with a probability of being 1 that is related linearly to the predictor\n",
        " via the logit funtion, that is $logit(p) = a*x + b$ (or $beta_1*x + beta_0$ if you prefer)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-15T10:08:02.667979Z",
          "start_time": "2020-07-15T10:08:02.534948Z"
        },
        "id": "S7QnGTGx9RDI"
      },
      "source": [
        "np.random.seed(1968)\n",
        "\n",
        "N = 4000\n",
        "x = normal (3,2,N)  # generate the x_n \n",
        "\n",
        "a = 0.6 \n",
        "b = -1.5 # this is the ground truth, which is unknown\n",
        "\n",
        "p = 1/(1+np.exp( -(a*x + b) )) # generate the p_n \n",
        "t = binomial(1,p, N)  # generate the targets according to p\n",
        "data = pd.DataFrame({'x':x, 't':t})\n",
        "\n",
        "data.plot.scatter('x','t',figsize=(8,8));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-15T10:08:03.524259Z",
          "start_time": "2020-07-15T10:08:03.470643Z"
        },
        "id": "9M0QNpNx9RDI"
      },
      "source": [
        "model = GLM.from_formula('t ~ x', data, family=Binomial())\n",
        "result = model.fit()\n",
        "result.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "variables": {
          "result.params[0]": {},
          "result.params[1]": {}
        },
        "id": "MO2MNOVE9RDI"
      },
      "source": [
        " Obviously x is very significant (and the Intercept is always significant)\n",
        "\n",
        "Therefore, our estimated model is\n",
        " $logit(p_n) ={{result.params[1]}}*x_n {{result.params[0]}}$\n",
        " quite close to the ground truth\n",
        "\n",
        " In general you get this as:\n",
        " \n",
        "  result.params\n",
        "\n",
        "Interpretation of the coefficients:\n",
        " \n",
        "- For a 1 unit increase in x, there is an increase in the odds for t by a factor of ..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-15T10:08:04.639507Z",
          "start_time": "2020-07-15T10:08:04.635562Z"
        },
        "id": "Ebuq0lpU9RDI"
      },
      "source": [
        "result.params"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-15T10:08:05.270944Z",
          "start_time": "2020-07-15T10:08:05.267321Z"
        },
        "id": "sOnZa8lY9RDJ"
      },
      "source": [
        "np.exp(result.params[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qzuIUPN9RDJ"
      },
      "source": [
        " that is almost doubling the odds (~82% more)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6C2qWzEt9RDK"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1E3SdxYU9RDK"
      },
      "source": [
        "## Example 4: Logistic regression for classifying spam mail"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxna2N599RDK"
      },
      "source": [
        " This example will also illustrate how to change the 'cut point' for prediction, when there is an \n",
        " interest in minimizing a particular source of errors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-15T10:08:07.673908Z",
          "start_time": "2020-07-15T10:08:07.635829Z"
        },
        "id": "dao3PSqT9RDK"
      },
      "source": [
        "spam = read_csv(\"spambase.data\", delimiter=',', header=None)\n",
        "file = open('spambase.names', 'r')\n",
        "spam.columns = [n.strip() for n in file.readlines()]\n",
        "\n",
        "spam.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5H2nmJVn9RDL"
      },
      "source": [
        "We do some basic pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-15T10:08:08.815204Z",
          "start_time": "2020-07-15T10:08:08.788695Z"
        },
        "id": "yWOoPQFA9RDL"
      },
      "source": [
        "spam.loc[:,'capital_run_length_average':'capital_run_length_total'] =\\\n",
        "        spam.loc[:,'capital_run_length_average':'capital_run_length_total'].\\\n",
        "                    apply(lambda x: np.log10(x+1))\n",
        "spam = spam[spam.word_freq_george==0]\n",
        "spam = spam[spam.word_freq_650==0]\n",
        "spam = spam[spam.word_freq_hp==0]\n",
        "spam = spam[spam.word_freq_hpl==0]\n",
        "spam =spam.drop(columns=['word_freq_george','word_freq_650',\n",
        "                         'word_freq_hp','word_freq_hpl'])\n",
        "spam['about_money']=spam.word_freq_free+spam.word_freq_business+\\\n",
        "spam.word_freq_credit+spam.word_freq_money\n",
        "spam=spam.drop(columns=['word_freq_free','word_freq_business',\n",
        "                        'word_freq_credit','word_freq_money'])\n",
        "Class = spam.Class   # move the Class column to the last position\n",
        "spam=spam.drop(columns=['Class'])\n",
        "spam['Class'] = Class\n",
        "\n",
        "spam.shape\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-15T10:08:09.310215Z",
          "start_time": "2020-07-15T10:08:09.305674Z"
        },
        "id": "vYFB48xw9RDM"
      },
      "source": [
        "np.random.seed(4321)\n",
        "train, test = train_test_split(spam, test_size=0.33)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xr2rB9hy9RDM"
      },
      "source": [
        "Fit a GLM in the learning data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-15T10:08:11.458942Z",
          "start_time": "2020-07-15T10:08:10.269445Z"
        },
        "scrolled": false,
        "id": "m7wJtaj19RDM"
      },
      "source": [
        "spamM1 = GLM(train.Class,\n",
        "             add_constant(train.loc[:,:'about_money']), \n",
        "             family=Binomial())\n",
        "resultM1 = spamM1.fit()\n",
        "resultM1.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AB8kIGYY9RDM"
      },
      "source": [
        "We can see that there are some variables that have small weights and are probably not very relevant. The R notebook uses stepwise variable selection to simplify the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsYRSJYV9RDN"
      },
      "source": [
        "Statsmodels does not have stepwise variable selection, but we can use crossvalidated Recursive Forward Elimination (RFE) with the implementation of logistic regression from scikit learn. RFE does the same thing as stepwise variable selection but uses accuracy to select the best model using cross validation. The implentation of logistic regression in scikit-learn is more sofisticated and uses regularization so the results will be different than in the R notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-15T10:08:24.189657Z",
          "start_time": "2020-07-15T10:08:18.988243Z"
        },
        "id": "-abUj0-e9RDN"
      },
      "source": [
        "# we use L1 regularization to make 0 a large number \n",
        "# of the weigths, the lower the C the more attributes will be discarded\n",
        "logreg = LogisticRegression(solver='liblinear',penalty='l1',C=1)\n",
        "#njobs = -1 means that all the cores from the CPU are used\n",
        "rfe = RFECV(estimator=logreg,cv=10,n_jobs=-1) \n",
        "rfe.fit(train.loc[:,:'about_money'],train.Class);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-15T10:08:26.353198Z",
          "start_time": "2020-07-15T10:08:26.334716Z"
        },
        "id": "LXKt0A8t9RDN"
      },
      "source": [
        "print('Features Selected:',rfe.n_features_)\n",
        "print('\\n Ranking of features')\n",
        "sel = pd.DataFrame({'features': train.columns[:-1],\n",
        "                    'ranking': rfe.ranking_, \n",
        "                    'selected':rfe.support_})\n",
        "sel.sort_values(by='ranking')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBF0rczl9RDO"
      },
      "source": [
        "We get the extimator from the RFE and the list of selected variable to slice the data matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-15T10:08:27.960673Z",
          "start_time": "2020-07-15T10:08:27.955838Z"
        },
        "id": "hEYvhtLZ9RDO"
      },
      "source": [
        "resultM1 = rfe.estimator_\n",
        "sel_features = list(sel.features[sel.selected])\n",
        "sel_features\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qy0Jwsi9RDO"
      },
      "source": [
        " We define now a convenience function:\n",
        "\n",
        " 'P' is a parameter; whenever our filter assigns spam with probability at least P then we predict spam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-15T10:08:29.476932Z",
          "start_time": "2020-07-15T10:08:29.472023Z"
        },
        "id": "NkW4DFlt9RDO"
      },
      "source": [
        "def spam_acc(P=0.5):\n",
        "    # We use predict_proba instead of prediction to obtain \n",
        "    # the probabilities of the classes and \n",
        "    # we select only the probability for class 1 as \n",
        "    # the other is just the complementary\n",
        "    \n",
        "    # Accuracy in training\n",
        "    pred = resultM1.predict_proba(train.loc[:,sel_features])[:,1]\n",
        "    lab_tr = [1 if i>=P else 0 for i in pred]\n",
        "    df_tr=confusion(train.Class,lab_tr, classes=['nospam','spam'])\n",
        "\n",
        "    # Accuracy in test\n",
        "    pred = resultM1.predict_proba(test.loc[:,sel_features])[:,1]\n",
        "    lab_ts = [1 if i>=P else 0 for i in pred]\n",
        "    df_ts=confusion(test.Class,lab_ts, classes=['nospam','spam'])\n",
        " \n",
        "    return df_tr, (1-accuracy_score(train.Class,lab_tr))*100,\\\n",
        "           df_ts, (1-accuracy_score(test.Class,lab_ts))*100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-15T10:08:30.360781Z",
          "start_time": "2020-07-15T10:08:30.303888Z"
        },
        "id": "fnnly-LJ9RDP"
      },
      "source": [
        "c_tr,e_tr,c_ts,e_ts= spam_acc()\n",
        "c_tr\n",
        "print(f'Training error: {e_tr}%')\n",
        "c_ts\n",
        "print(f'Test error: {e_ts}%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_0fKmh_9RDP"
      },
      "source": [
        " Although the errors are quite low still one could argue that we should try to lower the probability of predicting spam when it is not\n",
        " We can do this (at the expense of increasing the converse probability) by:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-15T10:08:31.539030Z",
          "start_time": "2020-07-15T10:08:31.488274Z"
        },
        "id": "GYEn1WMy9RDP"
      },
      "source": [
        "c_tr,e_tr,c_ts,e_ts= spam_acc(0.7)\n",
        "c_tr\n",
        "print(f'Training error: {e_tr}%')\n",
        "c_ts\n",
        "print(f'Test error: {e_ts}%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dybIlLM9RDQ"
      },
      "source": [
        " So we get a much better spam filter; notice that the filter has a very low probability of \n",
        "predicting spam when it is not (which is the delicate case), of about "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-07-15T10:08:32.774657Z",
          "start_time": "2020-07-15T10:08:32.769622Z"
        },
        "id": "8KzutHRr9RDQ"
      },
      "source": [
        "c_ts.loc['nospam','spam'] /c_ts.loc['nospam'].sum()*100"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}